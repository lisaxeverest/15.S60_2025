{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Advanced Optimization - Large Scale Optimization\n",
    "\n",
    "Matthew Brun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Pkg;\n",
    "# Pkg.add.([\"Convex\", \"JuMP\", \"Images\", \"DelimitedFiles\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "$\\textsf{Session 2: Large-Scale Optimization}$\n",
    "---\n",
    "\n",
    "* How to identify structure in large-scale problems\n",
    "  \n",
    "* Algorithms for parallelizing structured optimization problems\n",
    "  \n",
    "* Parallel computing in `Julia`\n",
    "\n",
    "* Optimization under memory contraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Structure and Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Key Idea**: Identify substructures of problem that are easy to solve and repeatedly solve structured subproblems\n",
    "\n",
    "* What is easy to solve (relative to full problem)?\n",
    "\n",
    "    - Contains fewer variables/constraints than full problem\n",
    "\n",
    "    - Has efficient algorithm (dynamic programming, network flow)\n",
    "\n",
    "    - Tractable class of problem (e.g. MINLP -> MILP + NLP)\n",
    "\n",
    "    - Limited interaction with other parts of the problem\n",
    "\n",
    "* How do we \"combine\" solutions from multiple subproblems?\n",
    "\n",
    "    - Utilize special algorithms designed for decomposition\n",
    "\n",
    "    - May need to solve subproblem instances many times or accept degraded solution quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure in Linear Programs\n",
    "\n",
    "* Linear programs have objectives that are separable in each variable (objective value is the sum of the objective contributed by each varaible)\n",
    "  \n",
    "  - This differs from functions with variable interactions, like $(x_1 + x_2)^2$\n",
    "\n",
    "* Constraints are given by $A x \\leq b$\n",
    "\n",
    "* Interactions between variables are shown in the sparsity pattern of matrix $A$\n",
    "\n",
    "    - Sparsity pattern = elements with nonzero entries\\\n",
    "    <img src=\"figures/largescale/sparsity_pattern.png\" alt=\"image-20220117142714899\" style=\"width: 300px;\" />\\\n",
    "    (Wikipedia)\n",
    "  \n",
    "* Sparsity pattern generalizes to nonlinear programs, consider indicating which variables appear in a constraint\n",
    "\n",
    "* Arbitrary ordering of matrix rows/columns may not reveal sparsity pattern \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Sparsity Patterns\n",
    "\n",
    "Group variables and constraints into \"blocks\"\n",
    "\n",
    "Common patterns:\n",
    "\n",
    "1. **Loose Coupling**: A few constraints link all variables, remaining constraints apply to blocks of variables\\\n",
    "    <img src=\"figures/largescale/loose_sparsity.png\" alt=\"image-20220117142714899\" style=\"width: 500px;\" />\n",
    "\n",
    "    - e.g. multiple locations with resource constraints\n",
    "    - Compatible with column generation algorithms\n",
    "\n",
    "1. **Two-Stage**: Some variables appear in many constraints, other variables appear in blocks of constraints\\\n",
    "    <img src=\"figures/largescale/twostage_sparsity.png\" alt=\"image-20220117142714899\" style=\"width: 500px;\" />\n",
    "\n",
    "    - e.g. two-stage stochastic program with recourse\n",
    "    - Compatible with row generation/Benders' decomposition\n",
    "   \n",
    "1. **Overlapping**: Constraints apply to a block of variables and \"adjacent\" blocks\\\n",
    "    <img src=\"figures/largescale/overlapping_sparsity.png\" alt=\"image-20220117142714899\" style=\"width: 500px;\" />\n",
    "\n",
    "    - e.g. multistage programming\n",
    "    - Compatible with stochastic dual dynamic programming (SDDP)\n",
    "\n",
    "Note: it is possible to convert between different patterns.  One approach is to introduce \"copies\" of variabes and identity constraints ($x = y$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Programming Example: Farmer's Problem [(Birge & Louveaux)](https://link.springer.com/book/10.1007/978-1-4614-0237-4)\n",
    "\n",
    "Consider a farmer who needs to decide what crops to plant, with the following considerations:\n",
    "\n",
    "* The crops are wheat, corn, and sugar cane\n",
    "  \n",
    "* 500 acres of land are available\n",
    "\n",
    "* Planting costs per acre are $\\$150$, $\\$230$, and $\\$260$, respectively\n",
    "\n",
    "* Wheat and corn can be sold for $\\$170$ and $\\$150$/ton, respectively\n",
    "\n",
    "* $6000$ tons of sugar cane can be sold for $\\$36$/ton, additional sugar cane can only be sold for $10/ton\n",
    "\n",
    "* The farmer needs $200$ tons of wheat and $240$ tons of corn to feed cattle\n",
    "\n",
    "* Additional wheat and corn can be purchased for $40\\%$ more than the sale price\n",
    "\n",
    "* Crop yield per acre planted depends on the weather conditions (\"good\", \"neutral\", or \"bad\") and is not known in advance; each condition is equally likely.  Yields are summarized in the following table:\n",
    "\n",
    "| Weather | Wheat Yield  | Corn Yield   | Sugar Cane Yield |\n",
    "| ------- | ------------ | ------------ | ---------------- |\n",
    "| Good    | 3 ton/acre   | 3.6 ton/acre | 24 ton/acre      |\n",
    "| Neutral | 2.5 ton/acre | 3 ton/acre   | 20 ton/acre      |\n",
    "| Bad     | 2 ton/acre   | 2.4 ton/acre | 16 ton/acre      |\n",
    "\n",
    "Let variables $x_w$, $x_c$, and $x_s$ denote the acres planted of each crop.  Variables $y_w$, $y_c$, and $y_s$ give the tons of each crop sold, and $z_w$ and $z_c$ the tons of wheat and corn purchased for feed.  Finally, $w$ gives the amount of excess sugar cane sold at the lower price.  As the actions $y,z,w$ depend on the crop yield, these variables are also indexed by scenario $s \\in \\{g,n,b\\} := S$.\n",
    "\n",
    "The problem can be modeled in the extensive form as follows:\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll} \\text{minimize} & 150 x_w + 230 x_c + 260 x_s + \\frac{1}{3}\\left (\\sum_{s \\in S} 170 (1.4 z_w^s - y_w^s) + 150 (1.4 z_c^s - y_c^s) - 36 y_s^s - 10 w_s^s \\right )\\\\\n",
    "\\text{subject to} & x_w + x_c + x_s \\leq 500 \\\\\n",
    "                    & x,y,z,w \\geq 0\\\\\n",
    "                    & \\textbf{Good Scenario}\\\\\n",
    "                    & 3 x_w - y_w^g + z_w^g \\geq 200\\\\\n",
    "                    & 3.6 x_c - y_c^g + z_c^g \\geq 240\\\\\n",
    "                    & 24 x_s - y_s^g - w_s^g \\geq 0\\\\\n",
    "                    & y_s^g \\leq 6000\\\\\n",
    "                    & \\textbf{Neutral Scenario}\\\\\n",
    "                    & 2.5 x_w - y_w^n + z_w^n \\geq 200\\\\\n",
    "                    & 3 x_c - y_c^n + z_c^n \\geq 240\\\\\n",
    "                    & 20 x_s - y_s^n - w_s^n \\geq 0\\\\\n",
    "                    & y_s^n \\leq 6000\\\\\n",
    "                    & \\textbf{Bad Scenario}\\\\\n",
    "                    & 2 x_w - y_w^b + z_w^b \\geq 200\\\\\n",
    "                    & 2.4 x_c - y_c^b + z_c^b \\geq 240\\\\\n",
    "                    & 16 x_s - y_s^b - w_s^b \\geq 0\\\\\n",
    "                    & y_s^b \\leq 6000\\\\\n",
    " \\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"data//largescale//farmer_data.jl\");\n",
    "\n",
    "using JuMP, Gurobi\n",
    "model = Model(Gurobi.Optimizer)\n",
    "\n",
    "@variable(model, x[crops] >= 0)\n",
    "@variable(model, y[crops, scenarios] >= 0)\n",
    "@variable(model, z[crops, scenarios] >= 0)\n",
    "@variable(model, w[crops, scenarios] >= 0)\n",
    "\n",
    "fix.([z[\"sugar\",s] for s in scenarios], 0, force=true)\n",
    "\n",
    "@constraint(model, sum(x) <= land_size)\n",
    "@constraint(model, [s in scenarios], y[\"sugar\", s] <= sugar_threshold)\n",
    "@constraint(model, [i in crops, s in scenarios], yield[(i,s)] * x[i] + z[i,s] - y[i,s] - w[i,s] >= feed_requirement[i])\n",
    "\n",
    "@objective(model, Min, 1/3 * sum(\n",
    "        sum(planting_cost[i] * x[i] + sale_price[i] * (purchase_multiplier * z[i,s] - y[i,s]) for i in crops) - sugar_second_price * w[\"sugar\",s]\n",
    "    for s in scenarios )\n",
    ")\n",
    "\n",
    "optimize!(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal solution is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in crops\n",
    "    println(c, \": \", value(x[c]))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms for Decomposition\n",
    "\n",
    "### Benders' Decomposition (BD)\n",
    "\n",
    "* Tailored for problems with two-stage structure\n",
    "\n",
    "* Replace each \"block\" with its value function\n",
    "\n",
    "* Iteratively approximate the value function with linear cuts\n",
    "  - Valid cuts are built from dual multipliers of each block\n",
    "\n",
    "* Consider the initial problem in the \"extensive form\":\n",
    "\\begin{array}{ll}\n",
    "\\text{minimize} & f(x) + \\sum_{\\omega \\in \\Omega} g_\\omega (y_\\omega)\\\\\n",
    "\\text{subject to} & (x,y_\\omega) \\in \\mathcal{Y}_\\omega \\quad \\forall  \\omega \\in \\Omega.\n",
    "\\end{array}\n",
    "\n",
    "* We instead solve the \"master problem\":\n",
    "\\begin{array}{ll}\n",
    "\\text{minimize} & f(x) + \\sum_{\\omega \\in \\Omega} v_\\omega\\\\\n",
    "\\text{subject to} & v_{\\omega} \\geq \\pi_j^T x \\quad \\forall j \\in J_\\omega,\\ \\omega \\in \\Omega.\n",
    "\\end{array}\n",
    "\n",
    "* For an incumbent solution $x'$, a new cut $\\pi$ can be computed from the solution to the problem\n",
    "\\begin{array}{ll}\n",
    "\\text{minimize} & g_{\\omega}(y)\\\\\n",
    "\\text{subject to} & (x',y) \\in \\mathcal{Y}_\\omega.\n",
    "\\end{array}\n",
    "\n",
    "* The master problem has fewer variables than the extensive form\n",
    "\n",
    "* The subproblems are separable and can be solved in parallel for each $\\omega$\n",
    "\n",
    "### Alternating Direction Method of Multipliers (ADMM)\n",
    "\n",
    "* Tailored for problems with linking constraints\n",
    "\n",
    "    - e.g. $x_1 = x_2$\n",
    "  \n",
    "* Add linear and quadratic penalty terms\n",
    "\n",
    "* Iteratively solve subproblems then update penalty multipliers\n",
    "\n",
    "* Consider the extensive form, with two blocks (for convenience):\n",
    "\\begin{array}{ll}\n",
    "\\text{minimize} & f(x) + g(y)\\\\\n",
    "\\text{subject to} & A x + B y = 0.\n",
    "\\end{array}\n",
    "\n",
    "* We instead consider the augmented Lagrangian function $$L(x,y,\\lambda) = f(x) + g(y) + \\lambda^T (A x + B y) + \\frac{\\rho}{2} \\|A x + B y \\|^2$$\n",
    "\n",
    "* ADMM takes the following iteration:\n",
    "    1.  $x_{k+1} \\in \\underset{x}{\\text{argmin}}\\ L(x,y_k,\\lambda_k)$\n",
    "    2.  $y_{k+1} \\in \\underset{x}{\\text{argmin}}\\ L(x_{k+1},y_k,\\lambda_k)$\n",
    "    3.  $\\lambda_{k+1} = \\lambda_k + \\rho (A x_{k+1} + B y_{k+1})$\n",
    "\n",
    "* These are **Gauss-Seidel** updates (not **Jacobian**), and are not parallelizable\n",
    "\n",
    "* If $f$ or $g$ are decomposable, the optimization within each step may be parallelized\n",
    "\n",
    "* Subproblems have quadratic objective terms\n",
    "\n",
    "### Progressive Hedging (PH)\n",
    "\n",
    "* Tailored for multistage stochastic problems with **nonanticipativity constraints**\n",
    "\n",
    "* Similar scheme to ADMM, penalizes difference from average iterate\n",
    "\n",
    "* Consider the extensive form:\n",
    "\\begin{array}{ll}\n",
    "\\text{minimize} & \\sum_{\\omega \\in \\Omega} p_\\omega (f(x_\\omega) + g_\\omega(y_\\omega))\\\\\n",
    "\\text{subject to} &x_{\\omega_1} = x_{\\omega_2} \\quad \\forall (\\omega_1,\\omega_2) \\in \\Omega^2.\n",
    "\\end{array}\n",
    "\n",
    "    - Require that $\\sum_{\\omega \\in \\Omega} p_{\\omega} = 1$\n",
    "  \n",
    "* PH takes the following iteration:\n",
    "    1.  $(x_{\\omega}^{k+1},y_{\\omega}^{k+1}) \\in \\underset{x,y}{\\text{argmin}}\\ f(x) + g_{\\omega} (y) + \\langle \\lambda_\\omega^k, x \\rangle + \\frac{\\rho}{2} \\|x - \\overline{x}^{k} \\|^2$ for all $\\omega$\n",
    "    2.  $\\overline{x}^{k+1} = \\sum_{\\omega \\in \\Omega} p_\\omega x_{\\omega}^{k+1}$\n",
    "    3.  $\\lambda_\\omega^{k+1} = \\lambda_\\omega^k + \\rho (x_\\omega^{k+1} - \\overline{x}^{k+1})$\n",
    "\n",
    "* Subproblems are parallelizable over scenarios $\\omega$\n",
    "\n",
    "* Subproblems have quadratic objective terms\n",
    "\n",
    "### Convergence \n",
    "\n",
    "* If the extensive form is convex, methods ADMM and PH converge to an optimal solution\n",
    "\n",
    "* Under additional assumptions (e.g. linearity, strong duality) BD converges to an optimal solution\n",
    "\n",
    "* If nonconvexity is present, convergence is not guaranteed\n",
    "\n",
    "    - Methods may still work as heuristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Computing for Implementation\n",
    "\n",
    "* Parallel computing runs multiple operations at the same time\n",
    "\n",
    "* Leverages modern computing architectures (multi-core CPU, multi-CPU HPC)\n",
    "\n",
    "* Adds runtime overhead from additional communication requirements\n",
    "\n",
    "### Multithreading\n",
    "\n",
    "* Julia natively supports multithreaded for loops\n",
    "\n",
    "* Start Julia with the argument `-t/--threads`, specifying the number of threads\n",
    "    \n",
    "    - Can change default thread number in VSCode settings (search Julia threads)\n",
    "\n",
    "* Prefacing a for loop with `Threads.@threads` runs a multithreaded for loop\n",
    "\n",
    "* **Thread safety**: avoid changing data that will be accessed by other threads, as order is not guaranteed\n",
    "\n",
    "    - Using custom tools (data locking, atomic operations), issues can be avoided\n",
    "  \n",
    "    - When calling other programs (e.g. solvers, Gurobi...) it is good practice to disable multithreading within the program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of available threads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run multithreaded for loop that tracks thread number by iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "a = zeros(n)\n",
    "Threads.@threads for i = 1:n\n",
    "    a[i] = Threads.threadid()\n",
    "end\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsafe multithreaded loop may give incorrect result.  \n",
    "The following code sums the values 1 to n in a threaded for loop (`s2`) and compares the result to the true value (`s1`).  Across repeated runs, `s2` may not give the correct result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200\n",
    "s1 = sum(1:n)\n",
    "function sum_threads(n)\n",
    "    s2 = 0\n",
    "    Threads.@threads for i = 1:n\n",
    "        s2 = s2 + i\n",
    "    end\n",
    "    return s2\n",
    "end\n",
    "s2 = sum_threads(n)\n",
    "println(\"s1: \", s1)\n",
    "println(\"s2: \", s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposed Stochastic Programming Example\n",
    " \n",
    "* In this example, we revisit the Farmer's problem\n",
    "\n",
    "* Problem is decomposed across scenarios by the progressive hedging algorithm\n",
    "\n",
    "* Subproblems are solved in parallel with multithreading\n",
    "\n",
    "* Note: Gurobi multithreading is disabled by setting the `Threads` solver argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, generate JuMP models for each scenario.  We construct a function that takes as input a scalar multiplier on the crop yields and returns the JuMP model for the scenario.  Then, we build a list containing the JuMP models.  Also, the objective functions are stored in a vector to facilitate the addition of penalty terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"data//largescale//farmer_data.jl\");\n",
    "\n",
    "using JuMP, Gurobi, Statistics\n",
    "\n",
    "function build_scenario_problem(scenario_multiplier)\n",
    "\n",
    "    model = Model(optimizer_with_attributes(\n",
    "        Gurobi.Optimizer,\n",
    "        \"Threads\"=>1\n",
    "    ))\n",
    "\n",
    "    @variable(model, x[crops] >= 0)\n",
    "    @variable(model, y[crops] >= 0)\n",
    "    @variable(model, z[crops] >= 0)\n",
    "    @variable(model, w[crops] >= 0)\n",
    "\n",
    "    fix.(z[\"sugar\"], 0, force=true)\n",
    "\n",
    "    @constraint(model, sum(x) <= land_size)\n",
    "    @constraint(model, y[\"sugar\"] <= sugar_threshold)\n",
    "    @constraint(model, [i in crops], (1 + scenario_multiplier) * yield[(i,\"neutral\")] * x[i] + z[i] - y[i] - w[i] >= feed_requirement[i])\n",
    "\n",
    "    @objective(model, Min, sum(planting_cost[i] * x[i] + sale_price[i] * (purchase_multiplier * z[i] - y[i]) for i in crops) - sugar_second_price * w[\"sugar\"])\n",
    "    return model\n",
    "\n",
    "end\n",
    "\n",
    "scenario_ids = 1:3\n",
    "scenario_multipliers = -0.2:0.2:0.2\n",
    "scenario_problems = [build_scenario_problem(scenario_multipliers[i]) for i in scenario_ids]\n",
    "scenario_objectives = [objective_function(scenario_problems[i]) for i in scenario_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, initialize the objects (penalty terms and average iterate) needed for PH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbar = Dict([(c,0.) for c in crops])\n",
    "lambda = Dict([((i,c),0.) for c in crops, i in scenario_ids])\n",
    "rho = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An iteration of PH proceeds as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in scenario_ids\n",
    "    @objective(\n",
    "        scenario_problems[i], \n",
    "        Min, \n",
    "        scenario_objectives[i] + sum(lambda[(i,c)] * scenario_problems[i][:x][c] + rho / 2 * (scenario_problems[i][:x][c] - xbar[c])^2 for c in crops)\n",
    "    )\n",
    "\n",
    "    optimize!(scenario_problems[i])\n",
    "\n",
    "end\n",
    "\n",
    "xbar = Dict([(c,mean(value.(scenario_problems[i][:x][c]) for i in scenario_ids)) for c in crops])\n",
    "\n",
    "for c in crops, i in scenario_ids\n",
    "    lambda[(i,c)] += rho * (value.(scenario_problems[i][:x][c]) - xbar[c])\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full code is as follows.  Note that a termination criterion is added, which checks convergence of the subproblem variables to the mean.  Additionally, the loop to solve the subproblems is multithreaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"data//largescale//farmer_data.jl\");\n",
    "\n",
    "using JuMP, Gurobi, Statistics\n",
    "\n",
    "function build_scenario_problem(scenario_multiplier)\n",
    "\n",
    "    model = Model(optimizer_with_attributes(\n",
    "        Gurobi.Optimizer,\n",
    "        \"Threads\"=>1,\n",
    "        MOI.Silent()=>true\n",
    "    ))\n",
    "\n",
    "    @variable(model, x[crops] >= 0)\n",
    "    @variable(model, y[crops] >= 0)\n",
    "    @variable(model, z[crops] >= 0)\n",
    "    @variable(model, w[crops] >= 0)\n",
    "\n",
    "    fix.(z[\"sugar\"], 0, force=true)\n",
    "\n",
    "    @constraint(model, sum(x) <= land_size)\n",
    "    @constraint(model, y[\"sugar\"] <= sugar_threshold)\n",
    "    @constraint(model, [i in crops], (1 + scenario_multiplier) * yield[(i,\"neutral\")] * x[i] + z[i] - y[i] - w[i] >= feed_requirement[i])\n",
    "\n",
    "    @objective(model, Min, sum(planting_cost[i] * x[i] + sale_price[i] * (purchase_multiplier * z[i] - y[i]) for i in crops) - sugar_second_price * w[\"sugar\"])\n",
    "    return model\n",
    "\n",
    "end\n",
    "\n",
    "scenario_ids = 1:3\n",
    "scenario_multipliers = -0.2:0.2:0.2\n",
    "scenario_problems = [build_scenario_problem(scenario_multipliers[i]) for i in scenario_ids]\n",
    "scenario_objectives = [objective_function(scenario_problems[i]) for i in scenario_ids]\n",
    "\n",
    "xbar = Dict([(c,0.) for c in crops])\n",
    "lambda = Dict([((i,c),0.) for c in crops, i in scenario_ids])\n",
    "rho = 1\n",
    "\n",
    "max_error = Inf\n",
    "\n",
    "itx = 1\n",
    "while max_error > 1e-8\n",
    "    Threads.@threads for i in scenario_ids\n",
    "        @objective(\n",
    "            scenario_problems[i], \n",
    "            Min, \n",
    "            scenario_objectives[i] + sum(lambda[(i,c)] * scenario_problems[i][:x][c] + rho / 2 * (scenario_problems[i][:x][c] - xbar[c])^2 for c in crops)\n",
    "        )\n",
    "\n",
    "        optimize!(scenario_problems[i])\n",
    "\n",
    "    end\n",
    "\n",
    "    xbar = Dict([(c,mean(value.(scenario_problems[i][:x][c]) for i in scenario_ids)) for c in crops])\n",
    "\n",
    "    max_error = 0\n",
    "    for c in crops, i in scenario_ids\n",
    "        term_error = (value.(scenario_problems[i][:x][c]) - xbar[c])\n",
    "        lambda[(i,c)] += rho * term_error\n",
    "\n",
    "        max_error = max(max_error, abs(term_error))\n",
    "    end\n",
    "    println(\"Iter \", itx, \": \", max_error)\n",
    "    itx += 1\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the solution aligns with that returned by the extensive form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message Passing Interface/`Distributed`\n",
    "\n",
    "* Allows for parallel processing across multiple nodes\n",
    "\n",
    "* Each task runs its own instance of the Julia program, behavior differs based on the process number\n",
    "\n",
    "* More flexible than multithreading\n",
    "\n",
    "    - A process doesn't need to wait for other threads to complete before proceeding\n",
    "    - Data can be shared across processes (message passsing)\n",
    "\n",
    "* Higher development cost than multithreading\n",
    "\n",
    "    - Program design requires more thought and customization\n",
    "\n",
    "* Message Passing Interface (MPI) is a parallel computing program that is accessible through many programming languges\n",
    "\n",
    "    - Package `MPI.jl` provides wrappers for Julia\n",
    "    - `mpi4py` is the corresponding Python package\n",
    "\n",
    "* `Distributed.jl` gives a high-level Julia alternative to MPI\n",
    "    - Number of processes is controlled with argument `-p`\n",
    "    - e.g. `julia -p 4`\n",
    "\n",
    "* MPI and Distributed are beyond the scope of this lesson, for more information, see:\n",
    "    - [Julia documentation on distributed computing](https://docs.julialang.org/en/v1/manual/distributed-computing/)\n",
    "    - [Github example for Distributed.jl](https://github.com/Arpeggeo/julia-distributed-computing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization under Memory Constraints\n",
    "\n",
    "* Some problems require large amounts of data that cannot be simultaneously loaded into memory (RAM)\n",
    "\n",
    "* e.g. large statistical problems, big data\n",
    "\n",
    "* Need to use algorithms and data structures that only use part of the data in memory at each step\n",
    "\n",
    "### Stochastic Gradient Descent (SGD)\n",
    "\n",
    "* Heuristic method used for large-scale nonconvex optimization in machine learning applications\n",
    "\n",
    "    - Applied for deep learning/neural network training\n",
    "\n",
    "* Samples **batches** of training data (stochastic), computes gradient on the batch (gradient descent)\n",
    "\n",
    "* Popular implementations (`Keras`, `TensorFlow`, `PyTorch`...) have implementations for memory management when loading data\n",
    "\n",
    "    - Typically, only a single batch is stored in memory\n",
    "\n",
    "### Block Coordinate Descent (BCD)\n",
    "\n",
    "* Method for convex optimization that applies **Gauss-Siedel** updates to subsets of coordinates (blocks)\n",
    "\n",
    "* Consider the extensive form:\n",
    "\\begin{array}{ll}\n",
    "\\text{minimize} & f(x_1,\\ldots,x_n)\\\\\n",
    "\\end{array}\n",
    "\n",
    "* The method uses the following update for all $i$:\\\n",
    "    $x_i^{k+1} \\in \\underset{x_i}{\\text{argmin}}\\ f(x_1^{k+1},\\ldots,x_{i-1}^{k+1},x_i,x_{i+1}^{k},\\ldots,x_n^{k})$\n",
    "\n",
    "* The update for the i-th coordinate fixes the next iterate for all preceeding coordinates and uses the current iterate for all following coordinates\n",
    "\n",
    "* BCD converges to the optimal solution in the convex smooth setting\n",
    "\n",
    "* Only the necessary data for solving for the i-th coordinate needs to be held in memory\n",
    "\n",
    "    - For structured problems, this can significantly reduce memory requirements\n",
    "\n",
    "### Large-Scale Linear Regression with BCD\n",
    "\n",
    "* Linear regression solves the problem\n",
    "\\begin{array}{ll}\n",
    "\\underset{\\theta}{\\text{minimize}} & \\|A \\theta - b\\|_2^2\\\\\n",
    "\\end{array}\n",
    "\n",
    "    - $A$ is a matrix of observations of the independent variables and $b$ is the vector of dependent variable observations\n",
    "\n",
    "    - Linear regression has a closed form solution: $\\theta^* = (A^T A)^{-1} A^T b$\n",
    "\n",
    "* If matrix $A$ contains too many variables/observations, it may be too large to be stored in memory\n",
    "\n",
    "* Applying BCD intelligently allows us to use a single row of $A$ for each coordinate update\n",
    "\n",
    "* Store the residual $r = A \\theta - b$\n",
    "\n",
    "* For incumbent residual $r$, the block update for coodinate i can be solved by\\\n",
    "$\\delta^* \\in \\underset{\\delta}{\\text{argmin}} \\|r + \\delta A_i\\|_2^2 \\qquad \\text{and} \\qquad \\theta = \\theta + \\delta^* \\mathbb{e}_i \\qquad \\text{and} \\qquad r = r + \\delta^* A_i$\\\n",
    "where $A_i$ is the $i$-th column of $A$\n",
    "\n",
    "* Note that $\\delta^*$ has a closed-form solution as a linear regression with a single variable\n",
    "\n",
    "### Wine Quality Dataset\n",
    "\n",
    "* We apply this method to the [wine quality dataset](https://archive.ics.uci.edu/dataset/186/wine+quality)\n",
    "\n",
    "    - Dependent variable: wine quality score on [0,10]\n",
    "    - Independent variables: qualities including acidity, pH, alcohol content..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This code converts the full CSV file into a CSV file for each column\n",
    "\n",
    "# using DelimitedFiles\n",
    "# mat = readdlm(\"data//largescale//winequality-white.csv\", ';')\n",
    "# for i in 1:length(mat[1,:])\n",
    "#     file_name = string(\"data//largescale//winequality-white//\", replace(mat[1,i], \" \"=>\"_\"), \".csv\")\n",
    "#     writedlm(file_name, mat[2:end,i], ';')\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we identify the predictor columns and the observations of the dependent variable.  We also initialize the model parameters to $0$ and take $r = b$, so that the residuals correspond to the paramters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DelimitedFiles, LinearAlgebra\n",
    "column_names = setdiff(replace.(readdir(\"data//largescale//winequality-white//\"), \".csv\" => \"\"), [\"quality\"])\n",
    "b = readdlm(\"data//largescale//winequality-white//quality.csv\")\n",
    "\n",
    "m = length(column_names)\n",
    "n = length(b)\n",
    "\n",
    "r = copy(b)\n",
    "r_prev = copy(r)\n",
    "θ = Dict((c_name,0.) for c_name in column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single iteration of block updates can be computed by the following code.  Each iteration loads a single column into memory, computes the change in the regression parameter, and updates the residual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c_name in column_names\n",
    "    c_data = readdlm(string(\"data//largescale//winequality-white//\", c_name, \".csv\"))\n",
    "    δ = - sum(c_data .* r) / sum(c_data .* c_data)\n",
    "    θ[c_name] += δ\n",
    "    r += δ .* c_data\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method iterates until no significant residual improvement is observed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm(r_prev) - norm(r) < 1e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full implementation is as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DelimitedFiles, LinearAlgebra\n",
    "column_names = setdiff(replace.(readdir(\"data//largescale//winequality-white//\"), \".csv\" => \"\"), [\"quality\"])\n",
    "b = readdlm(\"data//largescale//winequality-white//quality.csv\")\n",
    "\n",
    "m = length(column_names)\n",
    "n = length(b)\n",
    "\n",
    "r = -copy(b)\n",
    "θ = Dict((c_name,0.) for c_name in column_names)\n",
    "\n",
    "itx = 1\n",
    "while true\n",
    "    r_prev = r\n",
    "    for c_name in column_names\n",
    "        c_data = readdlm(string(\"data//largescale//winequality-white//\", c_name, \".csv\"))\n",
    "        δ = sum(c_data .* r) / sum(c_data .* c_data)\n",
    "        θ[c_name] += -δ\n",
    "        r -= δ .* c_data\n",
    "    end\n",
    "    if norm(r_prev) - norm(r) < 1e-7\n",
    "        break\n",
    "    end\n",
    "    itx += 1\n",
    "end\n",
    "\n",
    "println(\"# Iter: \", itx)\n",
    "println(\"Optimal Solution:\")\n",
    "θ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this problem is small enough to fit in memory, we can compute the optimal solution via the closed-form solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in = readdlm(\"data//largescale//winequality-white.csv\", ';')\n",
    "column_names = replace.(data_in[1,:], \" \" => \"_\")\n",
    "A = Matrix{Float64}(data_in[2:end,1:end-1])\n",
    "b = data_in[2:end,end]\n",
    "θ_true = inv(A' * A) * A' * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compare the difference in parameters as follows, and find that block coordinate descent identifies a comparable solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Absolute Coefficient Error:\")\n",
    "for i = 1:length(column_names)-1\n",
    "    println(\"\\t\", column_names[i], \": \", abs.(θ_true[i] - θ[column_names[i]]))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Relative Coefficient Error:\")\n",
    "for i = 1:length(column_names)-1\n",
    "    println(\"\\t\", column_names[i], \": \", abs.(θ_true[i] - θ[column_names[i]]) / θ_true[i])\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.2",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
